# Arceus Quick Reference Card

**Last Updated**: 2025-12-14

## ğŸš€ Quick Start

```bash
# Read comprehensive context FIRST
cat docs/ARCEUS_DEVELOPMENT_LOG.md

# Test single task
uv run python -m arceus.main --task-id 007bbfb7

# Run full evaluation
uv run python -m arceus.main --eval-all
```

## ğŸ“ File Map

```
arceus/
â”œâ”€â”€ solver.py              # Main orchestration (~1400 lines)
â”œâ”€â”€ cognitive_layers.py    # Three-layer architecture (714 lines)
â”œâ”€â”€ metrics.py             # Cost & memory tracking
â”œâ”€â”€ tui.py                 # Terminal UI
â”œâ”€â”€ config.py              # MODEL_PRICING dict
â”œâ”€â”€ test_time_training.py  # Stub (returns None)
â””â”€â”€ docs/
    â”œâ”€â”€ ARCEUS_DEVELOPMENT_LOG.md  # Complete history
    â”œâ”€â”€ ARCHITECTURE.md             # Visual diagrams
    â”œâ”€â”€ CLAUDE.md                   # Dev guidelines
    â”œâ”€â”€ QUICK_REFERENCE.md          # This file
    â””â”€â”€ SESSION_TEMPLATE.md         # Change template
```

## ğŸ§  Cognitive Flow

```
Task â†’ Strategy Selection â†’ [Deep Exploration?]
  YES â†’ Meta-Strategy â†’ Adaptive Memory â†’ Solution Guidance
  NO  â†’ Fast Solving
â†’ Generate Solution â†’ Verify â†’ [Fail?]
  YES â†’ Curiosity Reflection â†’ Retry
  NO  â†’ Success
â†’ Store (solution + guidance + context)
```

## ğŸ”‘ Key Patterns

### 1. Context Passing
```python
solving_context = {
    'use_deep_exploration': bool,
    'meta_strategy': dict,
    'memory_reflection': dict,
}
# Pass everywhere: generate_solution_with_memory(..., solving_context)
```

### 2. Cost Tracking
```python
metrics.add_llm_call(call_time_ms, tokens)
metrics.calculate_api_cost()  # Always!
```

### 3. Memory Tracking
```python
metrics.num_sessions_created += 1
metrics.num_messages_ingested += 1
metrics.add_peer_fact("peer_name")
```

### 4. Cognitive Layers
```python
from .cognitive_layers import CognitiveLayers
cognitive = CognitiveLayers(peer, client, tui)
guidance = await cognitive.get_solution_guidance_from_memory(...)
hypothesis["_solution_guidance"] = guidance  # Attach!
```

### 5. Store with Guidance
```python
await store_solution(
    task_id, solution, success, logger, tui, metrics,
    solving_context,  # NEW
    hypothesis.get("_solution_guidance")  # NEW
)
```

## ğŸ“Š Metrics Schema

```python
SolverMetrics:
    # Core
    task_id: str
    num_iterations: int

    # Cost
    model_name: str
    api_cost: float
    total_tokens: int

    # Memory
    num_sessions_created: int
    num_messages_ingested: int
    num_facts_stored: int
    facts_per_peer: Dict[str, int]
```

## ğŸ¯ Common Operations

| Task | File | Method/Line |
|------|------|-------------|
| Add metric | `metrics.py` | Add field to `SolverMetrics` |
| Track cost | `solver.py` | `metrics.calculate_api_cost()` |
| Cognitive layer | `cognitive_layers.py` | Add method to `CognitiveLayers` |
| Display metric | `tui.py:458-509` | Modify `_make_metrics_panel()` |
| Store solution | `solver.py:817-897` | `store_solution()` |
| Solution guidance | `cognitive_layers.py:532-713` | `get_solution_guidance_from_memory()` |

## ğŸ› Debug Checklist

- [ ] `solving_context` passed through pipeline?
- [ ] `metrics.calculate_api_cost()` after LLM calls?
- [ ] Memory counters incremented?
- [ ] `hypothesis["_solution_guidance"]` attached?
- [ ] `store_solution()` gets 8 parameters?
- [ ] Honcho client initialized?
- [ ] Async/await correct?
- [ ] JSON parsed with `re.search(r'\{.*\}', content, re.DOTALL)`?

## ğŸ“ Update Protocol

1. **Before**: Read `ARCEUS_DEVELOPMENT_LOG.md`
2. **During**: Follow patterns, track metrics, pass context
3. **After**: Add session to log using template

## ğŸ”— Links

- **Full Context**: `ARCEUS_DEVELOPMENT_LOG.md`
- **Architecture**: `ARCHITECTURE.md`
- **Dev Guide**: `CLAUDE.md`
- **Session Template**: `SESSION_TEMPLATE.md`
- **Honcho Docs**: https://docs.honcho.dev

## ğŸ’¡ Remember

Every change affects the learning loop:
```
Memory â†’ Guidance â†’ Solution â†’ Store â†’ Better Memory
```

**Always ask**: "How does this help the system learn?"
