---
title: "Peer Representations"
icon: "user-magnifying-glass"
sidebarTitle: "Representations"
---

A peer representation is the collection of reasoning Honcho has done about a peer over time. It's not a static profile or a snapshot--it's the accumulated output of continuous reasoning about every message that's been written to the peer. Representations evolve dynamically as new messages come in, with Honcho reasoning about them in the context of existing conclusions, reconciling contradictions and refining understanding.

When you write messages to Honcho, the reasoning models extract premises, draw conclusions, and generate insights. All of that reasoning gets stored as the peer's representation. Think of it as Honcho's understanding of who that peer is, what they care about, and how they behave, built through formal logic rather than simple storage.

## What's in a Representation?

A peer representation is made up of several types of artifacts that Honcho generates through reasoning:

**Conclusions** are insights derived through formal logic. Deductive conclusions are things Honcho can be certain about based on the premises. Inductive conclusions identify patterns across multiple messages. Abductive conclusions infer the simplest explanations for observed behavior. For example, if a user frequently mentions work deadlines and rarely mentions hobbies, Honcho might inductively conclude they're time-constrained or career-focused.

**Summaries** capture the essence of sessions. Short summaries are generated every 20 messages by default, and long summaries every 60 messages. These help compress conversation history into dense, queryable context.

**Peer cards** contain key biographical information. They essentially cache the most basic information about a peer (name, occupation, interests) to ensure the model never loses its grounding.

TODO: workshop this--The reasoning flows from premises to conclusions to higher-order artifacts. Each layer builds on what came before, creating a rich, queryable representation.

<Note>
For details on how reasoning works (deduction, induction, abduction), see the [Reasoning](/v2/documentation/core-concepts/reasoning) page.
</Note>

## Observation & Perspective-Taking

Honcho can build different representations based on what each peer observes. This enables sophisticated multi-peer scenarios where understanding is relative to what was actually witnessed.

There are two observation modes controlled by configuration:

**Honcho observing peers** (`observe_me`): When enabled (default), Honcho forms a representation of the peer based on all messages they've sent across all sessions. This is Honcho's understanding of that peer, built from everything they've said and done in your system. Set `observe_me: false` if you don't want Honcho to reason about that peer at all.

**Peers observing others** (`observe_others`): When enabled at the session level, a peer will form representations of other peers in that session based only on messages they've observed. If Alice and Opus are in a session together and Opus has `observe_others: true`, Opus will form a representation of Alice based solely on what Alice said in sessions Opus participated in. Opus's representation of Alice will be completely different from Carol's representation of Alice if they've observed different interactions.

![](/images/alice-bob.png)

The diagram above shows observation in practice. Honcho can observe each peer (forming representations based on everything they say), and individual peers can observe others (forming representations based only on what they witness in shared sessions).

Why would you want peers observing others? In multi-agent systems, different agents have access to different information. If Opus participates in sessions 1 and 2 with Alice, while Sonnet only participates in session 3, Opus's representation of Alice will be built from sessions 1 and 2, while Sonnet's representation will only include what happened in session 3. This information segmentation based on what each agent observed is critical for accurately modeling multi-agent scenarios.

<Note>
By default, `observe_me` is `true` (Honcho observes all peers) and `observe_others` is `false` (peers don't observe each other). You can configure both at the peer and session level depending on your needs.
</Note>

## Querying Representations

There are two main ways to access what Honcho knows about a peer:

The **get_context endpoint** (`/sessions/{session_id}/context`) retrieves structured context for a specific session, including recent messages, summaries, and reasoning about the peers involved. This is what you use when building the prompt for your agent's next response. The goal of get_context is to solve statefulness with one method--it gives you everything you need in one call to make your agent feel like it remembers.

The **chat endpoint** (`/peers/{peer_id}/chat`) lets you query representations with natural language. You can ask "What should I know about this user?" or "What motivates this peer?" and Honcho will retrieve relevant conclusions from the representation and synthesize an answer. Use this when you need super specific context that requires bespoke querying and synthesis--insights that might lie outside the distribution of what get_context provides. This is useful for steering agent behavior based on deep understanding of a peer.

Use get_context for standard contextualized responses. Use chat when you need to dig deeper or query for something specific.

## Why Representations Work

Statefulness is simulated through reconstruction of the past. Traditional systems reconstruct by retrieving stored facts when queries are semantically similar. Honcho reconstructs through reasoning, which changes everything.

Reasoning can surface insights never explicitly stated. If a user mentions they're saving for a house in one session and complains about subscription costs in another, Honcho can conclude they're budget-conscious without anyone saying it. Reasoning handles contradictions gracefully--when new information conflicts with old conclusions, it reconciles them instead of just accumulating more data. And reasoning enables prediction under uncertainty, inferring what's likely true based on patterns even when data is incomplete.

Humans reconstruct the past from imperfect recollections, then act on those reconstructions as if they were complete. Reasoning enables agents to do this perfectly. Representations produce an exhaustive, explicit record of what can be concluded about a peer--giving agents a complete foundation that humans can only pretend to have. That's what makes truly stateful agents possible.

## Next Steps

<CardGroup cols={2}>
  <Card title="Get an API Key" icon="key" href="https://app.honcho.dev">
    Sign up for the Honcho platform and start building
  </Card>
  <Card title="Quickstart" icon="rocket" href="/v2/documentation/introduction/quickstart">
    See representations in action with a working example
  </Card>
  <Card title="Architecture" icon="sitemap" href="/v2/documentation/core-concepts/architecture">
    Understand how representations fit into Honcho's architecture
  </Card>
  <Card title="Chat Endpoint" icon="comments" href="/v2/documentation/features/chat">
    Learn how to query representations with natural language
  </Card>
</CardGroup>
