---
title: "Peer Representations"
icon: "user-magnifying-glass"
sidebarTitle: "Representations"
---

TODO: this is all ai generated, i haven't reviewed it

A peer representation is the collection of reasoning Honcho has done about a peer over time. It's not a static profile or a snapshot--it's the accumulated output of continuous formal logical reasoning about everything that peer has said and done.

When you write messages to Honcho, the reasoning models extract premises, draw conclusions, and generate insights. All of that reasoning--observations, conclusions, summaries, peer cards--gets stored as the peer's representation. Think of it as Honcho's understanding of who that peer is, what they care about, and how they behave, built through formal logic rather than simple storage.

## What's in a Representation?

A peer representation is made up of several types of artifacts that Honcho generates through reasoning:

**Observations** are explicit premises extracted directly from messages. If a user says "I'm saving for a house," that's an observation. These serve as the foundation for further reasoning.

**Conclusions** are insights derived through formal logic. Deductive conclusions are things Honcho can be certain about based on the observations. Inductive conclusions identify patterns across multiple messages. Abductive conclusions infer the simplest explanations for observed behavior. For example, if a user frequently mentions work deadlines and rarely mentions hobbies, Honcho might inductively conclude they're time-constrained or career-focused.

**Summaries** capture the essence of sessions. Short summaries are generated every 20 messages by default, and long summaries every 60 messages. These help compress conversation history into dense, queryable context.

**Peer cards** are personality summaries and psychological profiles. They synthesize multiple conclusions into a cohesive understanding of the peer's characteristics, preferences, and behavioral patterns.

The reasoning flows from observations to conclusions to higher-order artifacts. Each layer builds on what came before, creating a rich, queryable representation.

## How Representations Are Built

Representations grow and evolve as you write data to Honcho. Here's the process:

Messages come in attributed to a peer and stored in a session. Those messages get enqueued for background reasoning. The reasoning models extract explicit premises from the message content, then use those premises to draw deductive conclusions. Those conclusions become the basis for inductive and abductive reasoning, generating patterns and explanations.

All of these artifacts--observations, conclusions, summaries--are indexed in vector storage as part of the peer's representation. When you query Honcho for context about a peer, it retrieves relevant pieces of that representation and composes them into a response.

Representations are containers for reasoning, not just memory storage. They're dynamic--as new messages come in, Honcho reasons about them in the context of existing conclusions, refining and extending its understanding. Contradictions get reconciled, patterns get reinforced or revised, and the representation becomes more accurate over time.

## Perspective-Taking

Honcho can model how different peers perceive each other based on their interactions. This enables sophisticated multi-peer scenarios where understanding is relative, not absolute.

There are two types of representations:

**Self-representations** are built from all messages a peer has sent across all their sessions. This is Honcho's understanding of the peer itself, informed by everything that peer has said and done in your system.

**Other-representations** are a peer's understanding of another peer, built only from messages they've observed from that peer. If Alice and Bob are in a session together, Bob's other-representation of Alice is based solely on what Alice said in sessions Bob was part of. Bob's representation of Alice might be completely different from Carol's representation of Alice if they've observed different interactions.

![](/images/perspectives.jpeg)

The diagram above shows how perspective-taking works in practice. Each peer can maintain their own representation (self) and representations of other peers they've interacted with, all based on what they've observed.

This perspective-taking ability is configured through the `observe_me` and `observe_others` settings. A peer's `observe_me` configuration controls whether Honcho forms a representation of them at all. The `observe_others` configuration (set at the session level) controls whether a peer should form representations of other peers in that session.

Why would you want this? In multi-agent systems, different agents might need different understandings of the same peer based on their role. A support agent might see a user as frustrated and time-sensitive, while a sales agent in a different context sees the same user as curious and exploratory. Perspective-taking lets you model these different viewpoints accurately.

## Querying Representations

There are two main ways to access what Honcho knows about a peer:

The **chat endpoint** (`/peers/{peer_id}/chat`) lets you query representations with natural language. You can ask "What should I know about this user?" or "What motivates this peer?" and Honcho will retrieve relevant conclusions from the representation and synthesize an answer. This is useful when you want insights about a peer to inform how your agent should interact with them.

The **get_context endpoint** (`/sessions/{session_id}/context`) retrieves structured context for a specific session, including recent messages, summaries, and reasoning about the peers involved. This is what you use when building the prompt for your agent's next response--it gives you everything you need in one call.

Use the chat endpoint when you want to understand a peer. Use get_context when you want to build a contextualized response.

## Why Representations Work

Traditional memory systems store facts and retrieve them when queries are semantically similar. Honcho's representation approach is fundamentally different.

Representations are built through reasoning, which means they can surface insights that were never explicitly stated. If a user mentions they're saving for a house in one session and complains about subscription costs in another, Honcho can conclude they're budget-conscious without anyone saying "I'm budget-conscious." The reasoning connects the dots.

Representations handle contradictions gracefully. If new information conflicts with old conclusions, the reasoning process reconciles them. Facts stored in a database just sit there--reasoning adapts.

Representations enable prediction under uncertainty. Traditional systems can only retrieve what was put in. Honcho can infer what's likely to be true based on patterns and logical reasoning, even when data is incomplete.

This is why representations are more powerful than memory--they're not just storage, they're understanding.

## Next Steps

<CardGroup cols={2}>
  <Card title="Get an API Key" icon="key" href="https://app.honcho.dev">
    Sign up for the Honcho platform and start building
  </Card>
  <Card title="Quickstart" icon="rocket" href="/v2/documentation/introduction/quickstart">
    See representations in action with a working example
  </Card>
  <Card title="Architecture" icon="sitemap" href="/v2/documentation/core-concepts/architecture">
    Understand how representations fit into Honcho's architecture
  </Card>
  <Card title="Chat Endpoint" icon="comments" href="/v2/documentation/features/chat">
    Learn how to query representations with natural language
  </Card>
</CardGroup>
