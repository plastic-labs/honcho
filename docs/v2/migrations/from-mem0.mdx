---
title: 'Migrating from Mem0'
description: 'A guide to migrate from Mem0 to Honcho'
icon: 'arrow-right-arrow-left'
---

Interested in transferring your data from Mem0 to Honcho? This guide covers why to switch, how to migrate your data and API comparisons.

<Note>
Got lots of data to migrate? Contact us at hello@plasticlabs.ai. We would love to help you!
</Note>

## Why Honcho?

**Inference, Not Just Storage** - Honcho builds evolving profiles of each participant through rich logic-based reasoning. Rather than retrieving facts, Honcho infers communication styles, values, patterns, and relationships - adapting to how users interact, not just what they say.

**Superior Performance** - Higher accuracy on memory retrieval benchmarks with faster inference times (more details soon!).

**Competitive Pricing** - Flexible pricing with generous free tier and volume discounts for high-throughput applications.

**Multi-Peer Sessions** - Native support for group conversations with multiple users and AI agents in a single session with configurable observation settings.

## Quick Migration

Migrate a single user's memories from Mem0 to Honcho in one script:

<Info>
Get your API key at [app.honcho.dev/api-keys](https://app.honcho.dev/api-keys). New accounts start with $100 credits. Plenty to start.
</Info>

<CodeGroup>
```python Python
# pip install mem0ai honcho-ai
from mem0 import MemoryClient
from honcho import Honcho

# Export from Mem0
mem0 = MemoryClient(api_key="your-mem0-api-key")
memories = mem0.get_all(filters={"user_id": "user123"}, page_size=100)

# Initialize Honcho
honcho = Honcho(api_key="your-honcho-api-key")
user = honcho.peer("user123")
session = honcho.session("imported")
session.add_peers([user])

# Import memories
for memory in memories:
    content = memory.get("memory") or memory.get("messages", [{}])[0].get("content", "")
    if content:
        session.add_messages([user.message(content)])

print(f"Migrated {len(memories)} memories!")
```

```typescript TypeScript
// npm install mem0ai @honcho-ai/sdk
import MemoryClient from "mem0ai";
import { Honcho } from "@honcho-ai/sdk";

// Export from Mem0
const mem0 = new MemoryClient({ apiKey: "your-mem0-api-key" });
const memories = await mem0.getAll({ filters: { user_id: "user123" }, page_size: 100 });

// Initialize Honcho
const honcho = new Honcho({ apiKey: "your-honcho-api-key"});
const user = await honcho.peer("user123");
const session = await honcho.session("imported");
await session.addPeers([user]);

// Import memories
for (const memory of memories) {
  const content = memory.memory || memory.messages?.[0]?.content || "";
  if (content) {
    await session.addMessages([user.message(content)]);
  }
}

console.log(`Migrated ${memories.length} memories!`);
```
</CodeGroup>

That's it! Your data is now in Honcho. Update your application code:

<CodeGroup>
```python Python
# Previous: Mem0
mem0.add(messages, user_id="user123")
mem0.search("query", user_id="user123")

# New: Honcho
session.add_messages([user.message("Hello!")])
user.search("query")
user.chat("What does this user prefer?")  # New! Honcho inference-powered
```

```typescript TypeScript
// Previous: Mem0
await mem0.add(messages, { user_id: "user123" });
await mem0.search("query", { user_id: "user123" });

// New: Honcho
await session.addMessages([user.message("Hello!")]);
await user.search("query");
await user.chat("What does this user prefer?");  // New! Honcho inference-powered
```
</CodeGroup>

## Step-by-Step Migration

Prefer a more detailed walkthrough? Follow these steps:

### 1. Export from Mem0

Use Mem0's [export API](https://docs.mem0.ai/cookbooks/essentials/exporting-memories) to retrieve your data:

```python
from mem0 import MemoryClient

client = MemoryClient(api_key="your-mem0-api-key")
memories = client.get_all(filters={"user_id": "user123"}, page_size=100)
```

### 2. Install the Honcho SDK

<CodeGroup>
```bash Python (uv)
uv add honcho-ai
```

```bash Python (pip)
pip install honcho-ai
```

```bash TypeScript (npm)
npm install @honcho-ai/sdk
```

```bash TypeScript (yarn)
yarn add @honcho-ai/sdk
```

```bash TypeScript (pnpm)
pnpm add @honcho-ai/sdk
```
</CodeGroup>

### 3. Initialize the Honcho Client

<CodeGroup>
```python Python
from honcho import Honcho

honcho = Honcho( api_key="your-api-key" )
```

```typescript TypeScript
import { Honcho } from '@honcho-ai/sdk';

const honcho = new Honcho({apiKey: process.env.HONCHO_API_KEY!});
```
</CodeGroup>

### 4. Import Your Data

<CodeGroup>
```python Python
for memory in memories:
    user_id = memory["filters"]["user_id"]
    peer = honcho.peer(user_id)
    session = honcho.session(f"imported-{user_id}")
    session.add_peers([peer])

    # Add message history
    if "messages" in memory:
        session.add_messages([
            peer.message(msg["content"]) for msg in memory["messages"]
        ])
    elif "memory" in memory:
        session.add_messages([peer.message(memory["memory"])])
```

```typescript TypeScript
for (const memory of memories) {
  const userId = memory.filters.user_id;
  const peer = await honcho.peer(userId);
  const session = await honcho.session(`imported-${userId}`);
  await session.addPeers([peer]);

  // Add message history
  if (memory.messages) {
    await session.addMessages(
      memory.messages.map((msg: any) => peer.message(msg.content))
    );
  } else if (memory.memory) {
    await session.addMessages([peer.message(memory.memory)]);
  }
}
```
</CodeGroup>

### 5. Update Your Application Code

Replace your Mem0 API calls with Honcho equivalents. See the [API Comparison](#api-comparison) and [Advanced Features](#advanced-features) sections below.

## API Comparison

| Mem0 | Honcho | Notes |
|------|--------|-------|
| `user_id` | `peer` | Supports both users and AI agents |
| `client.add()` | `session.add_messages()` | Session-scoped message storage |
| `client.search()` | `peer.search()` | Semantic & filter search |

These capabilities have no direct Mem0 equivalent:

| Honcho | Description |
|--------|-------------|
| `peer.chat()` | Query the representation of the peer, what it knows about its peers, nuanced preferences or general questions. Based on learned patterns, not just stored facts. |
| `peer.card()` | Get stable biographical facts about a peer (name, preferences, background) |
| `session.get_context()` | Retrieve optimized context with auto-summaries for LLM prompts |
| `session.working_rep()` | Get cached psychological analysis for a peer in this session (mental state, intentions, conclusions) |
| `session.get_summaries()` | Access auto-generated short and long session summaries |
| `SessionPeerConfig` | Configure observation settings (who learns about whom) |


## Advanced Features

Honcho enables capabilities not available in Mem0:

```python
# Multi-peer sessions
alice = honcho.peer("alice")
bob = honcho.peer("bob")
session = honcho.session("group-chat")
session.add_peers([alice, bob])

# Get cached working representation for a peer in this session
working_rep = session.working_rep(alice)

# Get biographical peer card
peer_card = alice.card()

# Session context with summaries for LLM prompts
context = session.get_context()

# Inference-powered queries (dialectic API)
insights = alice.chat("What communication style does Alice prefer?")
```

## Next Steps

<CardGroup cols={3}>
  <Card title="Architecture" icon="rocket" href="/v2/documentation/core-concepts/architecture">
    Understand peers and sessions
  </Card>
  <Card title="Dialectic API" icon="brain" href="/v2/documentation/core-concepts/features/dialectic-endpoint">
    Inference responses
  </Card>
  <Card title="Guides" icon="book" href="/v2/guides/overview">
    Integration examples
  </Card>
</CardGroup>

Questions? Join our [Discord](https://discord.gg/honcho) or open an issue on [GitHub](https://github.com/plastic-labs/honcho/issues).
