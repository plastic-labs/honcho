---
title: "Project Overview"
description: "Understanding Honcho's architecture and codebase for contributors"
---

# Project Overview

This guide provides contributors with an in-depth understanding of Honcho's codebase, architecture, and development practices.

## Project Structure

### Repository Layout

```
honcho/
├── src/                     # Main application code
│   ├── main.py             # FastAPI application entry point
│   ├── models.py           # SQLAlchemy database models
│   ├── schemas.py          # Pydantic schemas for API
│   ├── crud.py             # Database operations
│   ├── db.py               # Database configuration
│   ├── dependencies.py     # FastAPI dependencies
│   ├── security.py         # Authentication and security
│   ├── exceptions.py       # Custom exception handling
│   ├── routers/            # API route handlers
│   │   ├── workspaces.py
│   │   ├── peers.py
│   │   ├── sessions.py
│   │   ├── messages.py
│   │   └── keys.py
│   ├── deriver/            # Background processing system
│   │   ├── __main__.py     # Worker entry point
│   │   ├── consumer.py     # Message queue consumer
│   │   ├── queue.py        # Queue management
│   │   └── tom/            # Theory of Mind processing
│   └── utils/              # Utility modules
│       ├── cache.py
│       ├── history.py
│       └── model_client.py
├── tests/                  # Test suite
│   ├── routes/             # API endpoint tests
│   ├── integration/        # Integration tests
│   └── utils/              # Utility tests
├── migrations/             # Database migrations
├── docs/                   # Documentation
├── scripts/                # Utility scripts
└── docker-compose.yml      # Local development setup
```

## Core Components

### API Layer (`src/main.py`)

The FastAPI application serves as the main entry point:

```python
# Key responsibilities:
- Route registration and API versioning
- Middleware configuration (CORS, authentication)
- Exception handling and error responses
- OpenAPI documentation generation
- Health checks and monitoring endpoints
```

### Data Models (`src/models.py`)

SQLAlchemy models define the database schema:

**Core Entities:**
- `Workspace`: Top-level isolation containers
- `Peer`: Individual users or entities
- `Session`: Conversation or interaction contexts
- `Message`: Individual communication units
- `Document`: Vector storage for semantic search
- `Collection`: Organized document groups
- `QueueItem`: Background processing tasks

**Key Relationships:**
```python
Workspace 1:N Peer
Peer 1:N Session (through SessionPeer)
Session 1:N Message
Peer 1:N Collection 1:N Document
Workspace 1:N QueueItem
```

### API Schemas (`src/schemas.py`)

Pydantic models for request/response validation:

**Pattern Examples:**
```python
# Create schemas for input validation
class PeerCreate(BaseModel):
    name: str = Field(min_length=1, max_length=100)
    metadata: dict = Field(default_factory=dict)

# Response schemas for API output
class Peer(BaseModel):
    id: str
    name: str
    workspace_id: str
    created_at: datetime
    updated_at: datetime
    metadata: dict

# Update schemas for partial updates
class PeerUpdate(BaseModel):
    name: Optional[str] = None
    metadata: Optional[dict] = None
```

### Database Operations (`src/crud.py`)

CRUD operations following consistent patterns:

**Key Functions:**
- `create_*`: Insert new records
- `get_*`: Retrieve single records
- `get_*_by_*`: Query by specific fields
- `update_*`: Modify existing records
- `delete_*`: Remove records
- `search_*`: Complex queries and searches

**Example Pattern:**
```python
async def create_peer(
    db: AsyncSession,
    workspace_name: str,
    peer: schemas.PeerCreate,
) -> models.Peer:
    """Create a new peer in the specified workspace."""
    # Input validation and business logic
    # Database operations
    # Return created object
```

### Background Processing (`src/deriver/`)

The deriver system handles background tasks:

**Components:**
- **Queue Manager**: Enqueues and manages background tasks
- **Consumer**: Processes queue items using workers
- **TOM (Theory of Mind)**: AI-powered user analysis and insight generation

**Processing Types:**
- **Representation**: Generate user personality profiles
- **Summary**: Create conversation summaries
- **Facts**: Extract factual information

### Routers (`src/routers/`)

API endpoints organized by domain:

**Router Structure:**
```python
@router.post("/", response_model=schemas.Peer)
async def create_peer(
    workspace_name: str = Path(...),
    peer: schemas.PeerCreate = Body(...),
    db=Depends(get_db),
    current_workspace=Depends(get_current_workspace),
):
    """Create a new peer endpoint."""
```

**Common Patterns:**
- Path parameters for resource identification
- Body parameters for creation/updates
- Query parameters for filtering and pagination
- Dependency injection for database and authentication

## Development Patterns

### Async/Await Usage

Honcho uses async/await throughout for performance:

```python
# Database operations
async def get_peer(db: AsyncSession, peer_id: str) -> models.Peer:
    result = await db.execute(select(models.Peer).where(models.Peer.id == peer_id))
    return result.scalar_one_or_none()

# API endpoints
@router.get("/{peer_id}")
async def get_peer_endpoint(peer_id: str, db=Depends(get_db)):
    peer = await crud.get_peer(db, peer_id)
    return peer
```

### Error Handling

Consistent error handling using custom exceptions:

```python
# Custom exceptions in src/exceptions.py
class ResourceNotFoundException(HTTPException):
    def __init__(self, resource_type: str, resource_id: str):
        super().__init__(
            status_code=404,
            detail=f"{resource_type} with id '{resource_id}' not found"
        )

# Usage in CRUD operations
if not peer:
    raise ResourceNotFoundException("Peer", peer_id)
```

### Database Transactions

Proper transaction handling for data consistency:

```python
async def create_session_with_peers(
    db: AsyncSession,
    session_data: schemas.SessionCreate,
) -> models.Session:
    async with db.begin():
        # Create session
        session = await create_session(db, session_data)
        
        # Create session peers
        for peer_name, config in session_data.peers.items():
            await create_session_peer(db, session.id, peer_name, config)
        
        return session
```

### Dependency Injection

FastAPI dependencies for common operations:

```python
# Database session dependency
async def get_db():
    async with AsyncSessionLocal() as session:
        yield session

# Authentication dependency
async def get_current_workspace(
    authorization: str = Header(...),
    db=Depends(get_db),
) -> models.Workspace:
    # Validate JWT token and return workspace
    
# Usage in endpoints
async def endpoint(
    db=Depends(get_db),
    workspace=Depends(get_current_workspace),
):
    # Function implementation
```

## Key Technologies

### FastAPI

**Why FastAPI:**
- Automatic API documentation generation
- Type checking and validation
- High performance with async support
- Modern Python features (type hints, async/await)

**Key Features Used:**
- Path operations and route decorators
- Dependency injection system
- Request/response models with Pydantic
- Middleware for cross-cutting concerns

### SQLAlchemy 2.0

**Modern SQLAlchemy patterns:**
```python
# New style queries
stmt = select(models.Peer).where(models.Peer.workspace_id == workspace_id)
result = await db.execute(stmt)
peers = result.scalars().all()

# Relationship loading
stmt = select(models.Session).options(selectinload(models.Session.messages))
```

### PostgreSQL + pgvector

**Database Features:**
- ACID compliance for data integrity
- JSON columns for flexible metadata
- Vector similarity search with pgvector
- Full-text search capabilities
- Advanced indexing for performance

### Alembic Migrations

**Migration Patterns:**
```python
# Auto-generated migrations
def upgrade():
    op.create_table(
        'peers',
        sa.Column('id', sa.String(), nullable=False),
        sa.Column('name', sa.String(), nullable=False),
        sa.Column('workspace_id', sa.String(), nullable=False),
        sa.PrimaryKeyConstraint('id'),
        sa.ForeignKeyConstraint(['workspace_id'], ['workspaces.id'])
    )

# Data migrations when needed
def upgrade():
    # Schema changes
    op.add_column('peers', sa.Column('new_field', sa.String()))
    
    # Data migration
    connection = op.get_bind()
    connection.execute(text("UPDATE peers SET new_field = 'default'"))
```

## Testing Architecture

### Test Structure

**Test Organization:**
```python
tests/
├── conftest.py              # Shared fixtures
├── routes/                  # API endpoint tests
│   ├── test_peers.py       # Peer endpoint tests
│   └── test_sessions.py    # Session endpoint tests
├── integration/            # Cross-component tests
│   └── test_enqueue.py     # Background processing tests
└── utils/                  # Utility function tests
```

### Test Patterns

**Fixture Usage:**
```python
# conftest.py
@pytest.fixture
async def sample_workspace(db_session):
    workspace = await crud.create_workspace(
        db_session,
        schemas.WorkspaceCreate(name="test-workspace")
    )
    return workspace

# Test implementation
async def test_create_peer(client, sample_workspace):
    response = client.post(
        f"/v1/workspaces/{sample_workspace.name}/peers",
        json={"name": "test-peer"}
    )
    assert response.status_code == 200
```

### Integration Testing

**Database Testing:**
```python
# Test with real database operations
@pytest.mark.asyncio
async def test_deriver_processing(db_session):
    # Create test data
    workspace = await create_test_workspace(db_session)
    peer = await create_test_peer(db_session, workspace)
    
    # Trigger processing
    await enqueue_representation_task(db_session, peer.id)
    
    # Verify results
    status = await get_deriver_status(db_session, workspace.name, peer.name)
    assert status.total_work_units > 0
```

## Performance Considerations

### Database Optimization

**Query Optimization:**
- Use `select()` with specific columns when possible
- Implement proper indexing for frequently queried fields
- Use `selectinload()` for relationship loading
- Implement pagination for large result sets

**Connection Management:**
- Use async connection pooling
- Proper session management with context managers
- Avoid N+1 query problems

### Caching Strategy

**Redis Integration:**
```python
# Cache frequently accessed data
async def get_peer_with_cache(peer_id: str) -> models.Peer:
    # Check cache first
    cached = await redis_client.get(f"peer:{peer_id}")
    if cached:
        return Peer.parse_raw(cached)
    
    # Database lookup
    peer = await crud.get_peer(db, peer_id)
    
    # Cache result
    await redis_client.setex(
        f"peer:{peer_id}",
        3600,  # 1 hour TTL
        peer.json()
    )
    return peer
```

### Background Processing

**Queue Optimization:**
- Batch processing for efficiency
- Priority queues for important tasks
- Dead letter queues for failed items
- Monitoring and alerting for queue health

## Security Considerations

### Authentication

**JWT Token Validation:**
```python
def verify_token(token: str) -> dict:
    try:
        payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])
        return payload
    except JWTError:
        raise HTTPException(401, "Invalid token")
```

### Authorization

**Resource Access Control:**
```python
async def verify_workspace_access(
    workspace_name: str,
    token_payload: dict,
    db: AsyncSession,
) -> models.Workspace:
    # Verify user has access to workspace
    # Return workspace or raise 403
```

### Input Validation

**Pydantic Models:**
```python
class PeerCreate(BaseModel):
    name: str = Field(min_length=1, max_length=100, pattern=r"^[a-zA-Z0-9_-]+$")
    metadata: dict = Field(default_factory=dict, max_length=10000)
    
    @validator('metadata')
    def validate_metadata(cls, v):
        # Custom validation logic
        return v
```

## Deployment Architecture

### Container Strategy

**Docker Configuration:**
```dockerfile
# Multi-stage build for optimization
FROM python:3.11-slim as builder
# Build dependencies

FROM python:3.11-slim as runtime
# Runtime environment
```

### Environment Configuration

**Configuration Management:**
```python
# src/config.py
class Settings(BaseSettings):
    database_url: str
    openai_api_key: str
    jwt_secret: str
    
    class Config:
        env_file = ".env"

settings = Settings()
```

This project overview should help you understand Honcho's architecture and contribute effectively. For specific implementation details, refer to the code documentation and existing examples in the codebase. 